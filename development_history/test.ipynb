{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_RAW = \"train_X_languages_homework.json.txt\"\n",
    "TRAIN_LABEL_RAW = \"train_y_languages_homework.json.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    sentences = list()\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                sentence = json.loads(line)['text']\n",
    "                sentences.append(sentence)\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_label(path):\n",
    "    classifications = list()\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                classification = json.loads(line)['classification']\n",
    "                classifications.append(classification)\n",
    "        return classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = read_data(path = TRAIN_DATA_RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelset = read_label(path = TRAIN_LABEL_RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lacus class fames',\n",
       " 'στην Πλατεία του',\n",
       " 'מפני שטעו לחשוב',\n",
       " '• Florida •',\n",
       " '. Siehe auch : Liste der Landschaften in Nordrhein-Westfalen',\n",
       " 'Сицзян ) расположен',\n",
       " '. Deshalb wird',\n",
       " 'Uí Fiachrach · Uí Briúin · Uí Néill · Síl',\n",
       " 'v srednjeveški latinščini',\n",
       " 'menjadi embrio .',\n",
       " 'prevalentemente su testo',\n",
       " 'Anversa 1920 ·',\n",
       " ' Albania  •  Andora  •  Armenia  •  Austria  •  Azerbejdżan  •  Belgia  •  Bośnia i Hercegowina  •  Bułgaria  •  Chorwacja  •  Cypr  •  Czarnogóra  •  Czechy  •  Dania  •  Estonia  •  Finlandia  •  Francja  •  Grecja  •  Gruzja  •  Hiszpania  •  Holandia  •  Irlandia  •  Islandia  •  Liechtenstein  •  Litwa  •  Luksemburg  •  Łotwa  •  Macedonia  •  Malta  •  Mołdawia  •  Monako  •  Niemcy  •  Norwegia  •  Polska  •  Portugalia  •  Rosja  •  Rumunia  •  San Marino  •  Serbia  •  Słowacja  •  Słowenia  •  Szwajcaria  •  Szwecja  •  Turcja  •  Ukraina  •  Węgry  •  Wielka Brytania  •  Włochy ',\n",
       " 'acima , os',\n",
       " 'Krst pri Savici',\n",
       " 'čeprav so mu domači in strici duhovniki odtegovali denarno pomoč . Kljub temu mu je uspelo shajati , saj je bil od leta 1822 Knafljev štipendist , še vedno mu je pomagal stric Jožef , denar pa si je služil',\n",
       " '; den lovgivende makt , som ligger hos monarken og',\n",
       " 'advertisement addressed to members of the House of Representatives .',\n",
       " ', Java eta sistema eragile modernoak . ASCII karaktereen multzoan',\n",
       " 'Institut Verdaguer )',\n",
       " 'Minangkabau ( Jamee',\n",
       " 'soviéticas excepto Georgia , inclusive las 3 repúblicas que habían',\n",
       " 'адносна стварэння сумеснага',\n",
       " 'ser calibrados cunha',\n",
       " 'u društvu i životu čovjeka . Martin Luther postavljao je',\n",
       " 'kalırsanız elimden gelen',\n",
       " 'poveikio aplinkai pasekmių . Pasirenkant eksploatacijos nutraukimo būdą įtakos turėjo įvairūs veiksniai : ekonominiai , socialiniai , saugos aspektai , bei eksploatacijos nutraukimo darbų kitose branduolinėse elektrinėse vykdymo patirtis . Už nedelstiną išmontavimo būdą pasisakė ir Ignalinos AE atstovai ,',\n",
       " '. În timpul',\n",
       " 'Portuqaliyadan çoxlu sayda',\n",
       " '이력서가 촬영부가 아닌']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lorem',\n",
       " 'el',\n",
       " 'he',\n",
       " 'da',\n",
       " 'de',\n",
       " 'ru',\n",
       " 'de',\n",
       " 'hu',\n",
       " 'sl',\n",
       " 'id',\n",
       " 'it',\n",
       " 'it',\n",
       " 'pl',\n",
       " 'pt',\n",
       " 'sl',\n",
       " 'sl',\n",
       " 'no',\n",
       " 'ru',\n",
       " 'eu',\n",
       " 'ca',\n",
       " 'id',\n",
       " 'es',\n",
       " 'be',\n",
       " 'gl',\n",
       " 'sh',\n",
       " 'tr',\n",
       " 'lt',\n",
       " 'ro',\n",
       " 'az',\n",
       " 'ko']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelset[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_language(labelset):\n",
    "    label_count = dict()\n",
    "    for label in labelset:\n",
    "        if label in label_count:\n",
    "            label_count[label] += 1\n",
    "        else:\n",
    "            label_count[label] = 1\n",
    "    return label_count\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_count = count_language(labelset = labelset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lorem': 3366, 'el': 2765, 'he': 2306, 'da': 2982, 'de': 4697, 'ru': 4045, 'hu': 2734, 'sl': 1569, 'id': 1676, 'it': 4836, 'pl': 2053, 'pt': 2712, 'no': 2384, 'eu': 1774, 'ca': 3013, 'es': 5198, 'be': 2015, 'gl': 2141, 'sh': 2652, 'tr': 2510, 'lt': 1570, 'ro': 3014, 'az': 1920, 'ko': 1234, 'fr': 3979, 'en': 4531, 'vi': 3261, 'hr': 1867, 'ar': 4143, 'bg': 2774, 'hi': 2146, 'ja': 1728, 'nn': 1393, 'sk': 1079, 'uz': 889, 'ka': 1167, 'fa': 1984, 'cs': 2332, 'zh': 1690, 'sv': 2600, 'nl': 2465, 'kk': 1120, 'eo': 2010, 'ur': 913, 'et': 923, 'uk': 3430, 'hy': 2263, 'ceb': 307, 'fi': 1598, 'th': 1578, 'sr': 2027, 'la': 1255, 'vo': 412, 'ms': 1238, 'ce': 576, 'war': 547}\n"
     ]
    }
   ],
   "source": [
    "print(label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_char_utf(dataset):\n",
    "    char_count = dict()\n",
    "    for data in dataset:\n",
    "        for char in data:\n",
    "            if char in char_count:\n",
    "                char_count[char] += 1\n",
    "            else:\n",
    "                char_count[char] = 1\n",
    "    return char_count\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_count = count_char_utf(dataset = dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5697"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_n_gram(dataset, labelset, language, n = 2, k = 200):\n",
    "    # extract the top k frequent n-grams for certain language\n",
    "    # count all n-grams\n",
    "    n_gram_count = dict()\n",
    "    for data, label in zip(dataset, labelset):\n",
    "        if label == language:\n",
    "            # print(label)\n",
    "            length = len(data)\n",
    "            for i in range(length-n+1):\n",
    "                n_gram = data[i:i+n]\n",
    "                #print(n_gram)\n",
    "                if n_gram in n_gram_count:\n",
    "                    n_gram_count[n_gram] += 1\n",
    "                else:\n",
    "                    n_gram_count[n_gram] = 1\n",
    "    # extract the top k frequent n-grams from all the n-grams\n",
    "    n_gram_count_tuple = list()\n",
    "    for n_gram in n_gram_count:\n",
    "        n_gram_count_tuple.append((n_gram, n_gram_count[n_gram]))\n",
    "    n_gram_count_tuple.sort(key = lambda tup: tup[1], reverse = True)\n",
    "    number_n_gram = len(n_gram_count_tuple)\n",
    "    n_gram_top_k = list()\n",
    "    n_gram_top_k_occurrence = list()\n",
    "    for i in range(min(k, number_n_gram)):\n",
    "        n_gram_top_k.append(n_gram_count_tuple[i][0])\n",
    "        n_gram_top_k_occurrence.append(n_gram_count_tuple[i][1])\n",
    "    return n_gram_top_k, n_gram_top_k_occurrence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_gram_el, n_gram_el_occurence = extract_n_gram(dataset = dataset, labelset = labelset, language = 'el', n = 2, k = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_n_gram_all(dataset, labelset, languages, n = 2, k = 200):\n",
    "    # extract the top k frequent n-grams for all languages\n",
    "    # make them into on n_gram list\n",
    "    n_gram_list = list()\n",
    "    n_gram_occurrence = list()\n",
    "    for language in languages:\n",
    "        n_gram_top_k, n_gram_top_k_occurrence = extract_n_gram(\n",
    "            dataset = dataset, labelset = labelset, language = language, n = n, k = k)\n",
    "        n_gram_list += n_gram_top_k\n",
    "        \n",
    "    n_gram_list = list(set(n_gram_list))\n",
    "    \n",
    "    return n_gram_list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(label_count.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two_gram_list = extract_n_gram_all(\n",
    "    dataset = dataset, labelset = labelset, languages = list(label_count.keys()), n = 2, k = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1660"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(two_gram_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def n_gram_representation(sentence, n, n_gram_list):\n",
    "    sentence_n_grams = list()\n",
    "    length = len(sentence)\n",
    "    \n",
    "    for i in range(length-n+1):\n",
    "        #print(sentence[i:i+n])\n",
    "        sentence_n_grams.append(sentence[i:i+n])\n",
    "    sentence_n_grams = set(sentence_n_grams)\n",
    "    \n",
    "    \n",
    "    num_n_grams_all = len(n_gram_list)\n",
    "\n",
    "    \n",
    "    representation = np.zeros(num_n_grams_all)\n",
    "    \n",
    "    for i in range(num_n_grams_all):\n",
    "        if n_gram_list[i] in sentence_n_grams:\n",
    "            \n",
    "            representation[i] = 1.0\n",
    "    \n",
    "    \n",
    "    return representation\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a  = n_gram_representation(sentence = \"how ?\", n = 2, n_gram_list = two_gram_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_index_dict(n_gram_list):\n",
    "    index_dict = dict()\n",
    "    number_n_grams = len(n_gram_list)\n",
    "    for i in range(number_n_grams):\n",
    "        index_dict[n_gram_list[i]] = i\n",
    "        #print(i)\n",
    "    return index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two_gram_index_dict = feature_index_dict(n_gram_list  = two_gram_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1660"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(two_gram_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_n_gram_dataset(dataset, n, n_gram_list):\n",
    "    n_gram_dataset = np.zeros((len(dataset), len(n_gram_list)))\n",
    "    size_dataset = len(dataset)\n",
    "    for i in range(size_dataset):\n",
    "        #print(i)\n",
    "        sentence = dataset[i]\n",
    "        n_gram_dataset[i] = n_gram_representation(sentence, n, n_gram_list)\n",
    "        \n",
    "    return n_gram_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef prepare_n_gram_dataset(dataset, n, n_gram_index_dict):\\n    n_gram_dataset = np.zeros((len(dataset), len(n_gram_index_dict)))\\n    size_dataset = len(dataset)\\n    for i in range(size_dataset):\\n        #print(i)\\n        sentence = dataset[i]\\n        length = len(sentence)\\n        for j in range(length-n+1):\\n            #print(sentence[j:j+n])\\n            if sentence[j:j+n] in n_gram_index_dict:\\n                \\n                n_gram_dataset[i,n_gram_index_dict[sentence[j:j+n]]] = 1.0\\n        \\n    return n_gram_dataset\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def prepare_n_gram_dataset(dataset, n, n_gram_index_dict):\n",
    "    n_gram_dataset = np.zeros((len(dataset), len(n_gram_index_dict)))\n",
    "    size_dataset = len(dataset)\n",
    "    for i in range(size_dataset):\n",
    "        #print(i)\n",
    "        sentence = dataset[i]\n",
    "        length = len(sentence)\n",
    "        for j in range(length-n+1):\n",
    "            #print(sentence[j:j+n])\n",
    "            if sentence[j:j+n] in n_gram_index_dict:\n",
    "                \n",
    "                n_gram_dataset[i,n_gram_index_dict[sentence[j:j+n]]] = 1.0\n",
    "        \n",
    "    return n_gram_dataset\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_train = prepare_n_gram_dataset(dataset = dataset, n = 2, n_gram_list = two_gram_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lb = preprocessing.LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.fit(labelset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ar', 'az', 'be', 'bg', 'ca', 'ce', 'ceb', 'cs', 'da', 'de', 'el',\n",
       "       'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'gl', 'he', 'hi',\n",
       "       'hr', 'hu', 'hy', 'id', 'it', 'ja', 'ka', 'kk', 'ko', 'la', 'lorem',\n",
       "       'lt', 'ms', 'nl', 'nn', 'no', 'pl', 'pt', 'ro', 'ru', 'sh', 'sk',\n",
       "       'sl', 'sr', 'sv', 'th', 'tr', 'uk', 'ur', 'uz', 'vi', 'vo', 'war',\n",
       "       'zh'],\n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelset_onehot = lb.transform(labelset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelset_onehot[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(labelset)\n",
    "\n",
    "lb.classes_\n",
    "\n",
    "lb.transform([1, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(dataset_train_1[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(dataset_train_2[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = np.array([np.array([1,2]), np.array([3,4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c[1] = np.array([5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([[]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.append(a, np.array([[1,2,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  1.,  2.,  3.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(a,np.array([[1,2,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((100000, 2000)).nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
